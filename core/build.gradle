/* Copyright 2021 Radix Publishing Ltd incorporated in Jersey (Channel Islands).
 *
 * Licensed under the Radix License, Version 1.0 (the "License"); you may not use this
 * file except in compliance with the License. You may obtain a copy of the License at:
 *
 * radixfoundation.org/licenses/LICENSE-v1
 *
 * The Licensor hereby grants permission for the Canonical version of the Work to be
 * published, distributed and used under or by reference to the Licensor’s trademark
 * Radix ® and use of any unregistered trade names, logos or get-up.
 *
 * The Licensor provides the Work (and each Contributor provides its Contributions) on an
 * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied,
 * including, without limitation, any warranties or conditions of TITLE, NON-INFRINGEMENT,
 * MERCHANTABILITY, or FITNESS FOR A PARTICULAR PURPOSE.
 *
 * Whilst the Work is capable of being deployed, used and adopted (instantiated) to create
 * a distributed ledger it is your responsibility to test and validate the code, together
 * with all logic and performance of that code under all foreseeable scenarios.
 *
 * The Licensor does not make or purport to make and hereby excludes liability for all
 * and any representation, warranty or undertaking in any form whatsoever, whether express
 * or implied, to any entity or person, including any representation, warranty or
 * undertaking, as to the functionality security use, value or other characteristics of
 * any distributed ledger nor in respect the functioning or value of any tokens which may
 * be created stored or transferred using the Work. The Licensor does not warrant that the
 * Work or any use of the Work complies with any law or regulation in any territory where
 * it may be implemented or used or that it will be appropriate for any specific purpose.
 *
 * Neither the licensor nor any current or former employees, officers, directors, partners,
 * trustees, representatives, agents, advisors, contractors, or volunteers of the Licensor
 * shall be liable for any direct or indirect, special, incidental, consequential or other
 * losses of any kind, in tort, contract or otherwise (including but not limited to loss
 * of revenue, income or profits, or loss of use or data, or loss of reputation, or loss
 * of any economic or other opportunity of whatsoever nature or howsoever arising), arising
 * out of or in connection with (without limitation of any use, misuse, of any ledger system
 * or use made or its functionality or any performance or operation of any code or protocol
 * caused by bugs or programming or logic errors or otherwise);
 *
 * A. any offer, purchase, holding, use, sale, exchange or transmission of any
 * cryptographic keys, tokens or assets created, exchanged, stored or arising from any
 * interaction with the Work;
 *
 * B. any failure in a transmission or loss of any token or assets keys or other digital
 * artefacts due to errors in transmission;
 *
 * C. bugs, hacks, logic errors or faults in the Work or any communication;
 *
 * D. system software or apparatus including but not limited to losses caused by errors
 * in holding or transmitting tokens by any third-party;
 *
 * E. breaches or failure of security including hacker attacks, loss or disclosure of
 * password, loss of private key, unauthorised use or misuse of such passwords or keys;
 *
 * F. any losses including loss of anticipated savings or other benefits resulting from
 * use of the Work or any changes to the Work (however implemented).
 *
 * You are solely responsible for; testing, validating and evaluation of all operation
 * logic, functionality, security and appropriateness of using the Work for any commercial
 * or non-commercial purpose and for any reproduction or redistribution by You of the
 * Work. You assume all risks associated with Your use of the Work and the exercise of
 * permissions under this License.
 */

apply plugin: 'java'
apply plugin: 'application'
apply plugin: 'distribution'
apply plugin: 'project-report'
apply plugin: 'nebula.ospackage'
apply plugin: 'com.moowork.node'
apply plugin: 'org.sonarqube'
apply plugin: 'net.nemerosa.versioning'
apply plugin: 'com.palantir.git-version'

node {
    download = true
}

mainClassName = project.getProperties().get('overrideMainClassName', 'com.radixdlt.RadixNodeApplication')

startScripts {
    classpath = files('src/resources') + classpath
    // ^^ will prepend '$APP_HOME/lib/resources' to the classpath, which we'll use it as a pattern below
    doLast {
        def windowsScriptFile = file getWindowsScript()
        def unixScriptFile = file getUnixScript()
        windowsScriptFile.text = windowsScriptFile.text.replace('%APP_HOME%\\lib\\resources', '%RADIXDLT_HOME%')
        unixScriptFile.text = unixScriptFile.text.replace('$APP_HOME/lib/resources', '$RADIXDLT_HOME')
    }
}

sourceSets {
    integration {
        java {
            compileClasspath += main.output + test.output
            runtimeClasspath += main.output + test.output
            srcDir file('src/integration/java')
        }
        resources.srcDir file('src/integration/resources')
    }
}

processIntegrationResources {
    // Avoids an issue with the build picking up a duplicate MockMaker
    duplicatesStrategy = DuplicatesStrategy.EXCLUDE
}

configurations {
    integrationImplementation.extendsFrom testImplementation
}

task integrationTest(type: Test) {
    filter {
        includeTestsMatching "com.radixdlt.integration.steady_state.*"
    }
    testClassesDirs = sourceSets.integration.output.classesDirs
    classpath = sourceSets.integration.runtimeClasspath
    maxParallelForks = Runtime.runtime.availableProcessors().intdiv(2) ?: 1 //A greater number was tried, but the tests either failed or there was no gain in performance.
    mustRunAfter(test)
}

task targetedIntegrationTest(type: Test) {
    filter {
        includeTestsMatching "com.radixdlt.integration.targeted.*"
    }
    testClassesDirs = sourceSets.integration.output.classesDirs
    classpath = sourceSets.integration.runtimeClasspath
    // We're using all available processors here for now because we want to run all classes at the same time and they don't seem to be cpu intensive
    maxParallelForks = Runtime.runtime.availableProcessors()
    mustRunAfter(test)
}

task allIntegrationTest(type: Test) {
    testClassesDirs = sourceSets.integration.output.classesDirs
    classpath = sourceSets.integration.runtimeClasspath
    // We're using all available processors here for now because we want to run all classes at the same time and they don't seem to be cpu intensive
    maxParallelForks = Runtime.runtime.availableProcessors().intdiv(2) ?: 1
    mustRunAfter(test)
}

versionFile {
    mustRunAfter(processResources)
    // Path to the file to be written
    file = new File("$buildDir/resources/main", 'version.properties')
}

classes {
    dependsOn(versionFile)
}

jar {
    manifest {
        attributes 'Multi-Release': 'true'
    }
}

integrationTest {
    jacoco {
        // We don't want integration tests included in code coverage.
        enabled false
    }
}

jacocoTestReport {
    dependsOn test
    reports {
        xml.enabled true
        csv.enabled false
    }
}

dependencies {
    implementation project(':engine')
    implementation project(':common')
    implementation 'com.fasterxml.jackson.core:jackson-databind'

    implementation 'io.swagger:swagger-annotations:1.5.0'
    implementation "com.github.akarnokd:rxjava3-extensions"
    implementation 'io.reactivex.rxjava3:rxjava'
    implementation 'com.sleepycat:je'

    implementation 'com.lmax:disruptor'

    implementation 'commons-cli:commons-cli'
    implementation 'org.xerial.snappy:snappy-java'
    implementation 'io.netty:netty-all'
    implementation 'com.google.inject:guice'
    implementation 'com.google.inject.extensions:guice-grapher'

    implementation 'io.undertow:undertow-core'
    implementation 'com.stijndewitt.undertow.cors:undertow-cors-filter'
    implementation 'com.fasterxml.jackson.dataformat:jackson-dataformat-yaml'

    testImplementation 'org.awaitility:awaitility'
    testImplementation 'org.mockito:mockito-core'
    testImplementation 'junit:junit'
    testImplementation 'nl.jqno.equalsverifier:equalsverifier'
    testImplementation 'org.assertj:assertj-core'
    testImplementation 'org.reflections:reflections'
}

// More memory
tasks.withType(JavaExec) {
    jvmArgs = ['-Xmx1024m']
}

tasks.withType(Test){
    minHeapSize = "128m"
    maxHeapSize = "4096m"
}

// Compress distTar
tasks.withType(Tar) {
    compression = Compression.GZIP
}

ospackage {
    os = LINUX

    postInstall file('ospackage/postinst.sh')
    preUninstall file('ospackage/prerm.sh')
    postUninstall file('ospackage/postrm.sh')

    from("$buildDir/install/$name") {
        into "/opt/$name"
    }
    from("ospackage/${name}.service") {
        into "/etc/systemd/system"
    }

    buildDeb {
        dependsOn += [installDist]
        version = project.version.replaceAll('-', '~').replaceAll(/[^A-Za-z0-9.+:~-]/, '')
    }
    buildRpm {
        dependsOn += [installDist]
    }
}

/**
 * Display size of each dependency
 */
task depsize {
    doLast {
        final formatStr = "%,10.2f"
        final conf = configurations.default
        final size = conf.collect { it.length() / (1024 * 1024) }.sum()
        final out = new StringBuffer()
        out << 'Total dependencies size:'.padRight(45)
        out << "${String.format(formatStr, size)} Mb\n\n"
        conf.sort { -it.length() }
                .each {
            out << "${it.name}".padRight(45)
            out << "${String.format(formatStr, (it.length() / 1024))} kb\n"
        }
        println(out)
    }
}

/**
 * Manages the *.deb file in the docker directory
 */
task deb4docker(type: Copy, dependsOn: buildDeb) {
    def ospackageVersion = project.version.replaceAll('-', '~').replaceAll(/[^A-Za-z0-9.+:~-]/, '')

    from("$buildDir/distributions") {
        include "radixdlt_${ospackageVersion}_all.deb"
    }
    into project.file('../docker')
    doFirst {
        def names = [] as Set
        destinationDir.eachFileMatch(groovy.io.FileType.FILES, ~/radixdlt_.+_all\.deb/) {
            names << it.name
        }
        names.toSorted().each {
            def rip = new File(destinationDir, it)
            rip.delete()
            println "Deleted conflicting deb package: ${rip.name} ..."
        }
    }
}
